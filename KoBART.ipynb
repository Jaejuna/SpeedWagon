{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWc/Yz4yQwrMp05QsJGxj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaejuna/SpeedWagon/blob/main/KoBART.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/SKT-AI/KoBART#how-to-install"
      ],
      "metadata": {
        "id": "yArg9R8qAWTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX_UY-bVhE3D",
        "outputId": "9687352c-7ca3-4324-959e-acf4233551b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbCDWH-c2sbx",
        "outputId": "78553b39-37d2-4bd2-84ec-860f354ee29d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "import tensorflow"
      ],
      "metadata": {
        "id": "1EhP2tFGikkK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SKT-AI/KoBART.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNmGuzVEgSNx",
        "outputId": "b0b62d51-28a0-4388-c05c-33868ac6089e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoBART'...\n",
            "remote: Enumerating objects: 331, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 331 (delta 13), reused 14 (delta 13), pack-reused 303\u001b[K\n",
            "Receiving objects: 100% (331/331), 8.24 MiB | 16.51 MiB/s, done.\n",
            "Resolving deltas: 100% (176/176), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VzZHC3tng3gD",
        "outputId": "2aa9e62a-1a78-4727-fc82-a13e1c4701b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd KoBART"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ1ehGAcgcsp",
        "outputId": "4484587b-c976-4185-e92c-d011c596c2a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBART\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UA5RtWXakMQW",
        "outputId": "f584d66b-1e12-465d-8be5-21ef6396effa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg-u1CLUxRU4",
        "outputId": "eeaab512-2336-4b2a-ac21-537f5f0cbc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/nvfuser/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.0.1+cu118.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.7.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DnJe3cCxSbw",
        "outputId": "71f46468-f6f5-4c2e-c7ff-db5a42fd6141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PfLStjGgZlK",
        "outputId": "130ed515-4da8-489f-f59b-cb86a1be0ffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.26.140)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
            "Collecting pytorch-lightning==1.2.1 (from -r requirements.txt (line 3))\n",
            "  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m814.2/814.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAVaF2Ys2nuA",
        "outputId": "41c53d74-006f-4f4d-c4f7-18c9407e76e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.140-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.140 (from boto3)\n",
            "  Downloading botocore-1.29.140-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.140->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.140->boto3) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.140->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.140 botocore-1.29.140 jmespath-1.0.1 s3transfer-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbsqHpajTa4G",
        "outputId": "f40b74a9-baf2-415a-953a-68c4c5923295"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kobart import get_kobart_tokenizer\n",
        "kobart_tokenizer = get_kobart_tokenizer()\n",
        "kobart_tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ BART ì…ë‹ˆë‹¤.ğŸ¤£:)l^o\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ifOrRoATm0",
        "outputId": "7c477e16-cf19-49cf-ee13-53cedd52613f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBART/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['â–ì•ˆë…•í•˜', 'ì„¸ìš”.', 'â–í•œêµ­ì–´', 'â–B', 'A', 'R', 'T', 'â–ì…', 'ë‹ˆë‹¤.', 'ğŸ¤£', ':)', 'l^o']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/BOAZ_miniProject2/train.csv')\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/BOAZ_miniProject2/valid.csv')"
      ],
      "metadata": {
        "id": "3Vn0Bp9rjdfA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import re\n",
        "import torch\n",
        "from rouge import Rouge\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "DTeytsnnTmNV",
        "outputId": "e5ee2602-bcf3-4ca7-aa8e-5253fcd97f7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-15e55e1a57b5>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m from transformers import (\n\u001b[1;32m     12\u001b[0m     \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrameì„ Datasetìœ¼ë¡œ ì „í™˜\n",
        "import datasets\n",
        "train_data = Dataset.from_pandas(train_df) \n",
        "val_data = Dataset.from_pandas(val_df)\n",
        "test_samples = Dataset.from_pandas(val_df)\n",
        "\n",
        "print(train_data)\n",
        "print(val_data)\n",
        "print(test_samples)"
      ],
      "metadata": {
        "id": "LvoIbVRDtYPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "ab708bc4-3f12-465a-9685-83c032a2e51e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ba57b633e5a6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DataFrameì„ Datasetìœ¼ë¡œ ì „í™˜\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "kobart_tokenizer = get_kobart_tokenizer()\n",
        "model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model())\n",
        "text = \"\"\"\n",
        "1ì¼ ì˜¤í›„ 9ì‹œê¹Œì§€ ìµœì†Œ 20ë§Œ3220ëª…ì´ ì½”ë¡œë‚˜19ì— ì‹ ê·œ í™•ì§„ëë‹¤. ë˜ë‹¤ì‹œ ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡ìœ¼ë¡œ, ì‚¬ìƒ ì²˜ìŒ 20ë§Œëª…ëŒ€ì— ì§„ì…í–ˆë‹¤.\n",
        "ë°©ì—­ ë‹¹êµ­ê³¼ ì„œìš¸ì‹œ ë“± ê° ì§€ë°©ìì¹˜ë‹¨ì²´ì— ë”°ë¥´ë©´ ì´ë‚  0ì‹œë¶€í„° ì˜¤í›„ 9ì‹œê¹Œì§€ ì „êµ­ ì‹ ê·œ í™•ì§„ìëŠ” ì´ 20ë§Œ3220ëª…ìœ¼ë¡œ ì§‘ê³„ëë‹¤.\n",
        "êµ­ë‚´ ì‹ ê·œ í™•ì§„ì ìˆ˜ê°€ 20ë§Œëª…ëŒ€ë¥¼ ë„˜ì–´ì„  ê²ƒì€ ì´ë²ˆì´ ì²˜ìŒì´ë‹¤.\n",
        "ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡ì€ ì§€ë‚œ 23ì¼ ì˜¤í›„ 9ì‹œ ê¸°ì¤€ 16ë§Œ1389ëª…ì´ì—ˆëŠ”ë°, ì´ë¥¼ ë¬´ë ¤ 4ë§Œ1831ëª…ì´ë‚˜ ì›ƒëŒì•˜ë‹¤. ì „ë‚  ê°™ì€ ì‹œê°„ ê¸°ë¡í•œ 13ë§Œ3481ëª…ë³´ë‹¤ë„ 6ë§Œ9739ëª… ë§ë‹¤.\n",
        "í™•ì§„ì í­ì¦ì€ 3ì‹œê°„ ì „ì¸ ì˜¤í›„ 6ì‹œ ì§‘ê³„ì—ì„œë„ ì˜ˆê²¬ëë‹¤.\n",
        "ì˜¤í›„ 6ì‹œê¹Œì§€ ìµœì†Œ 17ë§Œ8603ëª…ì´ ì‹ ê·œ í™•ì§„ë¼ ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡(24ì¼ 13ë§Œ8419ëª…)ì„ ê°ˆì•„ì¹˜ìš´ ë° ì´ì–´ ì´ë¯¸ ì§ì „ 0ì‹œ ê¸°ì¤€ ì—­ëŒ€ ìµœë‹¤ ê¸°ë¡ë„ ë„˜ì–´ì„°ë‹¤. ì—­ëŒ€ ìµœë‹¤ ê¸°ë¡ì€ ì§€ë‚œ 23ì¼ 0ì‹œ ê¸°ì¤€ 17ë§Œ1451ëª…ì´ì—ˆë‹¤.\n",
        "17ê°œ ì§€ìì²´ë³„ë¡œ ë³´ë©´ ì„œìš¸ 4ë§Œ6938ëª…, ê²½ê¸° 6ë§Œ7322ëª…, ì¸ì²œ 1ë§Œ985ëª… ë“± ìˆ˜ë„ê¶Œì´ 12ë§Œ5245ëª…ìœ¼ë¡œ ì „ì²´ì˜ 61.6%ë¥¼ ì°¨ì§€í–ˆë‹¤. ì„œìš¸ê³¼ ê²½ê¸°ëŠ” ëª¨ë‘ ë™ì‹œê°„ëŒ€ ê¸°ì¤€ ìµœë‹¤ë¡œ, ì²˜ìŒìœ¼ë¡œ ê°ê° 4ë§Œëª…ê³¼ 6ë§Œëª…ì„ ë„˜ì–´ì„°ë‹¤.\n",
        "ë¹„ìˆ˜ë„ê¶Œì—ì„œëŠ” 7ë§Œ7975ëª…(38.3%)ì´ ë°œìƒí–ˆë‹¤. ì œì£¼ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì§€ì—­ì—ì„œ ëª¨ë‘ ë™ì‹œê°„ëŒ€ ìµœë‹¤ë¥¼ ìƒˆë¡œ ì¼ë‹¤.\n",
        "ë¶€ì‚° 1ë§Œ890ëª…, ê²½ë‚¨ 9909ëª…, ëŒ€êµ¬ 6900ëª…, ê²½ë¶ 6977ëª…, ì¶©ë‚¨ 5900ëª…, ëŒ€ì „ 5292ëª…, ì „ë¶ 5150ëª…, ìš¸ì‚° 5141ëª…, ê´‘ì£¼ 5130ëª…, ì „ë‚¨ 4996ëª…, ê°•ì› 4932ëª…, ì¶©ë¶ 3845ëª…, ì œì£¼ 1513ëª…, ì„¸ì¢… 1400ëª…ì´ë‹¤.\n",
        "ì§‘ê³„ë¥¼ ë§ˆê°í•˜ëŠ” ìì •ê¹Œì§€ ì‹œê°„ì´ ë‚¨ì•„ìˆëŠ” ë§Œí¼ 2ì¼ 0ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë°œí‘œë  ì‹ ê·œ í™•ì§„ì ìˆ˜ëŠ” ì´ë³´ë‹¤ ë” ëŠ˜ì–´ë‚  ìˆ˜ ìˆë‹¤. ì´ì— ë”°ë¼ ìµœì¢… ì§‘ê³„ë˜ëŠ” í™•ì§„ì ìˆ˜ëŠ” 21ë§Œëª… ì•ˆíŒì„ ê¸°ë¡í•  ìˆ˜ ìˆì„ ì „ë§ì´ë‹¤.\n",
        "í•œí¸ ì „ë‚  í•˜ë£¨ ì„ ë³„ì§„ë£Œì†Œì—ì„œ ì´ë¤„ì§„ ê²€ì‚¬ëŠ” 70ë§Œ8763ê±´ìœ¼ë¡œ ê²€ì‚¬ ì–‘ì„±ë¥ ì€ 40.5%ë‹¤. ì–‘ì„±ë¥ ì´ 40%ë¥¼ ë„˜ì€ ê²ƒì€ ì´ë²ˆì´ ì²˜ìŒì´ë‹¤. í™•ì‚°ì„¸ê°€ ê³„ì† ê±°ì„¸ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì–˜ê¸°ë‹¤.\n",
        "ì´ë‚  0ì‹œ ê¸°ì¤€ ì‹ ê·œ í™•ì§„ìëŠ” 13ë§Œ8993ëª…ì´ì—ˆë‹¤. ì´í‹€ ì—°ì† 13ë§Œëª…ëŒ€ë¥¼ ì´ì–´ê°”ë‹¤.\n",
        "\"\"\"\n",
        "text = text.replace('\\n', ' ')\n",
        "\n",
        "inputs = kobart_tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "raw_input_ids = kobart_tokenizer.encode(text)\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "aTR4MyaVdvP2",
        "outputId": "bdb9a179-39f0-4399-b4be-3114dcb2f4c6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/KoBART/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
            "/content/KoBART/.cache/kobart_base_cased_ff4bda5738.zip[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"ë‹¤.ë‹¤.ë‹¤.ë‹¤.ë‹¤.ë‹¤.ë‹¤. ìµœì†Œ 20ë§Œ3220ëª…ì´ ì½”ë¡œë‚˜19ì— ì‹ ê·œ í™•ì§„ëë‹¤. ë˜ë‹¤ì‹œ ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡ìœ¼ë¡œ, ì‚¬ìƒ ì²˜ìŒ 20ë§Œëª…ëŒ€ì— ì§„ì…í–ˆë‹¤. ë°©ì—­ ë‹¹êµ­ê³¼ ì„œìš¸ì‹œ ë“± ê° ì§€ë°©ìì¹˜ë‹¨ì²´ì— ë”°ë¥´ë©´ ì´ë‚  0ì‹œë¶€í„° ì˜¤í›„ 9ì‹œê¹Œì§€ ì „êµ­ ì‹ ê·œ í™•ì§„ìëŠ” ì´ 20ë§Œ3220ëª…ìœ¼ë¡œ ì§‘ê³„ëë‹¤. êµ­ë‚´ ì‹ ê·œ í™•ì§„ì ìˆ˜ê°€ 20ë§Œëª…ëŒ€ë¥¼ ë„˜ì–´ì„  ê²ƒì€ ì´ë²ˆì´ ì²˜ìŒì´ë‹¤. ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡ì€ ì§€ë‚œ 23ì¼ ì˜¤í›„ 9ì‹œ ê¸°ì¤€ 16ë§Œ1389ëª…ì´ì—ˆëŠ”ë°, ì´ë¥¼ ë¬´ë ¤ 4ë§Œ1831ëª…ì´ë‚˜ ì›ƒëŒì•˜ë‹¤. ì „ë‚  ê°™ì€ ì‹œê°„ ê¸°ë¡í•œ 13ë§Œ3481ëª…ë³´ë‹¤ë„ 6ë§Œ9739ëª…ì´ë‚˜ ì›ƒëŒì•˜ë‹¤. ì „ë‚  ê°™ì€ ì‹œê°„ ê¸°ë¡í•œ 13ë§Œ3481ëª…ë³´ë‹¤ë„ 6ë§Œ9739ëª… ë§ë‹¤. í™•ì§„ì í­ì¦ì€ 3ì‹œê°„ ì „ì¸ ì˜¤í›„ 6ì‹œ ì§‘ê³„ì—ì„œë„ ì˜ˆê²¬ëë‹¤. ì˜¤í›„ 6ì‹œê¹Œì§€ ìµœì†Œ 17ë§Œ8603ëª…ì´ ì‹ ê·œ í™•ì§„ë¼ ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡(24ì¼ 13ë§Œ8419ëª…)ì„ ê°ˆì•„ì¹˜ìš´ ë° ì´ì–´ ì´ë¯¸ ì§ì „ 0ì‹œ ê¸°ì¤€ ì—­ëŒ€ ìµœë‹¤ ê¸°ë¡ë„ ë„˜ì–´ì„°ë‹¤. ì—­ëŒ€ ìµœë‹¤ ê¸°ë¡ì€ ì§€ë‚œ 23ì¼ 0ì‹œ ê¸°ì¤€ 17ë§Œ1451ëª…ì´ì—ˆë‹¤. 17ê°œ ì§€ìì²´ë³„ë¡œ ë³´ë©´ ì„œìš¸ 4ë§Œ6938ëª…, ê²½ê¸° 6ë§Œ7322ëª…, ì¸ì²œ 1ë§Œ985ëª… ë“± ìˆ˜ë„ê¶Œì´ 12ë§Œ5245ëª…ìœ¼ë¡œ ì „ì²´ì˜ 61.6%ë¥¼ ì°¨ì§€í–ˆë‹¤. ì„œìš¸ê³¼ ê²½ê¸°ëŠ” ëª¨ë‘ ë™ì‹œê°„ëŒ€ ê¸°ì¤€ ìµœë‹¤ë¡œ, ì²˜ìŒìœ¼ë¡œ ê°ê° 4ë§Œëª…ê³¼ 6ë§Œëª…ì„ ë„˜ì–´ì„°ë‹¤. ë¹„ìˆ˜ë„ê¶Œì—ì„œëŠ” 7ë§Œ7975ëª…(38.3%)ì´ ë°œìƒí–ˆë‹¤. ì œì£¼ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì§€ì—­ì—ì„œ ëª¨ë‘ ë™ì‹œê°„ëŒ€ ìµœë‹¤ë¥¼ ìƒˆë¡œ ì¼ë‹¤. ë¶€ì‚° 1ë§Œ890ëª…, ê²½ë‚¨ 9909ëª…, ëŒ€êµ¬ 6900ëª…, ê²½ë¶ 6977ëª…, ì¶©ë‚¨ 5900ëª…, ì¶©ë‚¨ 5900ëª…, ëŒ€ì „ 5292ëª…, ì „ë¶ 5150ëª…, ìš¸ì‚° 5141ëª…, ëŒ€êµ¬ 5130ëª…, ê²½ë¶ 4996ëª…, ì „ë‚¨ 4996ëª…, ê°•ì› 4932ëª…, ê´‘ì£¼ 3845ëª…, ì „ë‚¨ 4996ëª…, ê°•ì› 4932ëª…, ì¶©ë¶ 3845ëª…, ì œì£¼ 1513ëª…, ì„¸ì¢… 1400ëª…ì´ë‹¤. ì§‘ê³„ë¥¼ ë§ˆê°í•˜ëŠ” ìì •ê¹Œì§€ ì‹œê°„ì´ ë‚¨ì•„ìˆëŠ” ë§Œí¼ 2ì¼ 0ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë°œí‘œë  ì‹ ê·œ í™•ì§„ì ìˆ˜ëŠ” ì´ë³´ë‹¤ ë” ëŠ˜ì–´ë‚  ìˆ˜ ìˆë‹¤. ì´ì— ë”°ë¼ ìµœì¢… ì§‘ê³„ë˜ëŠ” í™•ì§„ì ìˆ˜ëŠ” 21ë§Œëª… ì•ˆíŒì„ ê¸°ë¡í•  ìˆ˜ ìˆì„ ì „ë§ì´ë‹¤. í•œí¸ ì „ë‚  í•˜ë£¨ ì„ ë³„ì§„ë£Œì†Œì—ì„œ ì´ë¤„ì§„ ê²€ì‚¬ëŠ” 70ë§Œ8763ê±´ìœ¼ë¡œ ê²€ì‚¬ ì–‘ì„±ë¥ ì€ 40.5%ë‹¤. ì–‘ì„±ë¥ ì´ 40%ë¥¼ ë„˜ì€ ê²ƒì€ ì´ë²ˆì´ ì²˜ìŒì´ë‹¤. í™•ì‚°ì„¸ê°€ ê³„ì† ê±°ì„¸ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì–˜ê¸°ë‹¤. ì´ë‚  0ì‹œ ê¸°ì¤€ ì‹ ê·œ í™•ì§„ìëŠ” 13ë§Œ8993ëª…ì´ì—ˆë‹¤. ì´í‹€ ì—°ì† 13ë§Œëª…ëŒ€ë¥¼ ì´ì–´ê°”, ì´í‹€ ì—°ì† 13ë§Œëª…ëŒ€ë¥¼ ì´ì–´ê°”'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.iloc[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "SFLkCUtmj8Ph",
        "outputId": "c6e4b699-59ee-4334-b54f-f14887f8bec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì›ƒê¸´ê²Œ 20ë…„ë™ì•ˆ... ë°”ë¡œ ì˜† ê°€ê²Œ ì£¼ì°¨ì¥ì—ì„œ ê°™ì´ ê·¸ ê°ìíƒ•ì§‘ ì£¼ì°¨ë„ í–ˆì—ˆëŠ”ë° ê·¸ ê°€ê²Œì—ì„œ ì´ì œ ëª»ëŒ€ê²Œí•´ì„œ; ì¡¸ì§€ì—...ê°ìíƒ•ì§‘ ì£¼ì°¨ ì—†ì–´ì§ ã…œã…œ í— ì˜ìƒí•˜ëŠ” ì¼ ìˆì—ˆë‚˜? ë­..ì•„ë¬´ë˜ë„ ê·¸ ê°ìíƒ•ì§‘ì´ ì¥ì‚¬ ì˜ë˜ë‹ˆê¹Œ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë°°ì•„íŒŒì„œ.. ì•„.. ê·¸ë ‡ë‹¤ê³  ê°ìíƒ•ì§‘ì„ ì•ˆê°„ë‹¤í•´ì„œ ê·¸ ê°€ê²ŒëŠ” ì•ˆê°ˆê±°ê°™ì€ë°; ê±°ê¸°ëŠ”..ë­” ëŠ¥ì´ë²„ì„¯ ì˜¤ë¦¬ì „ê³¨? ë­ ì´ëŸ°ê±°ë¼ ëŒ€ì¤‘ì ì´ì§„ ì•Šì–ì•„ ì•„ ì ì‹¬ìœ¼ë¡œ íˆ¬ë¨¸ì¹˜..'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "kobart_tokenizer = get_kobart_tokenizer()\n",
        "model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtAaQUCAlxi5",
        "outputId": "0880b411-f0bc-4624-f1e3-11dc016d392b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/KoBART/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
            "/content/KoBART/.cache/kobart_base_cased_ff4bda5738.zip[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs = kobart_tokenizer(train.iloc[0,0], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "text = train.iloc[0,0]\n",
        "raw_input_ids = kobart_tokenizer.encode(text)\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "1-YiS1LUj3J4",
        "outputId": "f5e7fcd9-39b8-4cc0-b9da-df752d6fe03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì›ƒê¸´ê²Œ 20ë…„ë™ì•ˆ... ë°”ë¡œ ì˜† ê°€ê²Œ ì£¼ì°¨ì¥ì—ì„œ ê°™ì´ ê·¸ ê°ìíƒ•ì§‘ ì£¼ì°¨ë„ í–ˆì—ˆëŠ”ë° ê·¸ ê°€ê²Œì—ì„œ ì´ì œ ëª»ëŒ€ê²Œí•´ì„œ; ì¡¸ì§€ì—... ì¡¸ì§€ì—...ê°ìíƒ•ì§‘ ì£¼ì°¨ ì—†ì–´ì§  í— ì˜ìƒí•˜ëŠ” ì¼ ìˆì—ˆë‚˜? ë­..ì•„ë¬´ë˜ë„ ê·¸ ê°ìíƒ•ì§‘ì´ ì¥ì‚¬ ì˜ë˜ë‹ˆê¹Œ á„á„á„á„á„á„á„á„á„ ê·¸ë ‡ë‹¤ê³  ê°ìíƒ•ì§‘ì„ ì•ˆê°„ë‹¤í•´ì„œ ê·¸ ê°€ê²ŒëŠ” ì•ˆê°ˆê±°ê°™ì€ë°; ê±°ê¸°ëŠ”..ë­” ì•„ ì˜† ê°€ê²Œ ì£¼ì°¨ì¥ì—ì„œ ê°™ì´ ê·¸ ê°ìíƒ•ì§‘ ì£¼ì°¨ë„ í–ˆì—ˆëŠ”ë° ê°™ì´ ê·¸ ê°ìíƒ•ì§‘ ì£¼ì°¨ë„ í–ˆì—ˆëŠ”ë° ê·¸ ê°€ê²Œì—ì„œ ì´ì œ ëª»ëŒ€ê²Œí•´ì„œ; ì¡¸ì§€ì—... ê°ìíƒ•ì§‘ ì£¼ì°¨ ì—†ì–´ê²Œí•´ì„œ; ì¡¸ì§€ì—...ê°ìíƒ•ì§‘ ì£¼ì°¨ ì—†ì–´ì§  í— ì˜ìƒí•˜ëŠ” ì¼ ìˆì—ˆë‚˜? ë­..ì•„ë¬´ë˜ë„ ê·¸ ê°ìíƒ•ì§‘ì´ ì¥ì‚¬ ì˜ë˜ë‹ˆê¹Œ á„á„á„á„á„á„á„á„á„á„á„á„á„á„á„ ë°°ì•„íŒŒì„œ.. ì•„.. ê·¸ë ‡ë‹¤ê³  ê°ìíƒ•ì§‘ì„ ì•ˆê°„ë‹¤í•´ì„œ ê·¸ ê°€ê²ŒëŠ” ì•ˆê°ˆê±°ê°™ì€ë°; ê±°ê¸°ëŠ”..ë­” ëŠ¥ì´ë²„ì„¯ ì˜¤ë¦¬ì „ê³¨? ë­ ì´ëŸ°ê±°ë¼ ëŒ€ì¤‘ì ì´ì§„ ì•Šì–ì•„ ì•„ ì ì‹¬ìœ¼ë¡œ íˆ¬ë¨¸ì¹˜.. ì•„ ì ì‹¬ìœ¼ë¡œ íˆ¬ë¨¸ì¹˜.. ì•„ ì ì‹¬ìœ¼ë¡œ íˆ¬ë¨¸ì¹˜.... ì•„ë¨¸ì¹˜.. ì•„ìŒ..ê°ìíƒ•ì§‘ ì¥ì‚¬ ì˜ë˜ë‹ˆê¹Œ ì¥ì‚¬ ì˜ë˜ë‹ˆê¹Œ á„á„á„á„á„á„á„á„á„á„á„á„ ë°°ì•„íŒŒì„œ.. ì•„ ì ì‹¬ìœ¼ë¡œ íˆ¬ë¨¸ì¹˜....ë­” ëŠ¥ì´ë²„ì„¯ ì˜¤ë¦¬ì „ê³¨? ë­ ì´ëŸ°ê±°ë¼ ëŒ€ì¤‘ì ì´ì§„ ì•Šì–ì•„ ì•„ ì ì‹¬ìœ¼ë¡œ íˆ¬ë¨¸ì¹˜...... ì ì‹¬ìœ¼ë¡œ íˆ¬ë¨¸ì¹˜............ê°ìíƒ•ì§‘ ì£¼ì°¨ ì—†ì–´ì§....ê°ìíƒ•ì§‘ ì£¼ì°¨ ì—†ì–´ì§  í— ì˜ìƒí•˜ëŠ” ì¼ ìˆì—ˆë‚˜? ë­..ì•„ë¬´ë˜ë„ ê·¸ ê°ìíƒ•ì§‘ì´ ì¥ì‚¬ ì˜ë˜ë‹ˆê¹Œ á„á„á„á„á„á„á„á„á„ ë°°ì•„íŒŒì„œ.. ì•„.. ê·¸ë ‡ë‹¤ê³  ê°ìíƒ•ì§‘ì„ ì•ˆê°„ë‹¤í•´ì„œ ê·¸ ê°€ê²ŒëŠ” ì•ˆê°ˆê±°ê°™ì€ë°.. ì•„.. ê·¸ë ‡ë‹¤ê³  ê°ìíƒ•ì§‘ì„ ì•ˆê°„ë‹¤í•´ì„œ ê·¸ ê°€ê²ŒëŠ” ì•ˆê°ˆê±°ê°™ì€ë°; ê±°ê¸°ëŠ”..ë­” ëŠ¥ì´ë²„ì„¯ ì˜¤ë¦¬ì „ê³¨? ë­ ì´ëŸ°ê±°ë¼ ëŒ€ì¤‘ì ì´ì§„ ì•Šì–ì•„ ì•„'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs = kobart_tokenizer(train.iloc[0,0], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "text = train.iloc[1,0]\n",
        "raw_input_ids = kobart_tokenizer.encode(text)\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "cReBfdQLqOph",
        "outputId": "69c130d7-1660-4e1b-acc0-a934488e499e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì•„ê¹Œ ë³´ë‹ˆê¹ ë¡œì¼“ í”„ë ˆì‹œ ì‡ë“œë¼ #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ë‚˜ë„ ë°¥ ë¬´ê±°ìš” í˜¸ì•µ ì•¼ ì œì£¼ë„ëŠ” ë¡œì¼“ë°°ì†¡ê°€ëŠ¥í•´? ê¸€ì„ ë³´ê³ ì˜¬ê²Œ ì–´ì œ ìš´ì „í• ë•Œ ë³´ë‹ˆë”´ ì¿ íŒ¡ ë¨¸ ì‡ê¸´ í•˜ë˜ë° ìš´ì „í•˜ëŠ”ë° í°ì„ ì™œ ë³´ë‚˜ ë³´ë‹ˆ ì–´ì œ ìš´ì „í• ë•Œ ë³´ë‹ˆë”´ ì¿ íŒ¡ ë¨¸ ì‡ê¸´ í•˜ë˜ë° ìš´ì „í•˜ëŠ”ë° í°ì„ ì™œ ë³´ë‚˜ ë³´ë‹ˆ #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ì¼ë‹¨ ì—¬ê¸´ ì•ˆë¼ ì•„ë‹ˆ ìš´ì „í•˜ê³  ì§€ë‚˜ê°€ëŠ”ë° ì¿ íŒ¡ ë¬¼ë¥˜ì„¼í„°ê°€ ì‡ë”ë¼ë„ ì œì£¼ì‹œ ìª½ì— ê·¸ ë¡œì¼“ë°°ì†¡ ë§êµ¬ ë‹¤ë¥¸ íƒë°°ë¡œ ì²œì²œíˆë¼ë„ ì™€? á„€á„…ì„....??????? ë‚˜ë„ ë°¥ ë¬´ê±°ìš” í˜¸ì•µ ì•¼ ì œì£¼ë„ëŠ” ë¡œì¼“ë°°ì†¡ê°€ëŠ¥í•´? ê¸€ì„ ë³´ê³ ì˜¬ê²Œ ì–´ì œ ìš´ì „í• ë•Œ ë³´ë‹ˆë”´ ì¿ íŒ¡ ë¨¸ ì‡ê¸´ í•˜ë˜ë° ìš´ì „ê¸´ í•˜ë˜ë° ìš´ì „í•˜ëŠ”ë° í°ì„ ì™œ ë³´ë‚˜ ë³´ë‹ˆ #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ì¼ë‹¨ ì—¬ê¸´ ì•ˆë¼ ì•„ë‹ˆ ì¿ íŒ¡ ë¨¸ ì‡ê¸´ í•˜ë˜ë° ìš´ì „í•˜ëŠ”ë° í°ì„ ì™œ ë³´ë‚˜ ë³´ë‹ˆ #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ì¼ë‹¨ ì—¬ê¸´ ì•ˆë¼ ì•„ë‹ˆ ìš´ì „í•˜ê³  ì§€ë‚˜ê°€ëŠ”ë° ì¿ íŒ¡ ë¬¼ë¥˜ì„¼í„°ê°€ ì‡ë”ë¼ë„ ì œì£¼ì‹œ ìª½ì— ê·¸ ë¡œì¼“ë°°ì†¡ ë§êµ¬ ë‹¤ë¥¸ íƒë°°ë¡œ ì²œì²œíˆë¼ë„ ì™€? á„€á„…ì„....?? ì²œì²œíˆë¼ë„ ì™€? á„€á„…ì„....?????? á„€á„…ì„....???? ë‚˜ë„ ë°¥ ë¬´ê±°ìš” í˜¸ì•µ ì•¼ ì œì£¼ë„ëŠ” ë¡œì¼“ë°°ì†¡ê°€ëŠ¥í•´? ê¸€ì„ ë³´ê³ ì˜¬ê²Œ ì–´ì œ ìš´ì „í• ë•Œ ë³´ë‹ˆë”´ ì¿ íŒ¡ ë¨¸ ì‡ê¸´ í•˜ë˜ë° ìš´ì „í•˜ëŠ”ë° í°ì„ ì™œ ë³´ë‚˜ ë³´ë‹ˆ #@ì‹œìŠ¤í…œ#ì‚¬ì§„#ì‚¬ì§„# ì¼ë‹¨ ì—¬ê¸´ ì•ˆë¼ ì•„ë‹ˆ ìš´ì „í•˜ê³  ì§€ë‚˜ê°€ëŠ”ë° ì¿ íŒ¡ ë¬¼ë¥˜ì„¼í„°ê°€ ì‡ë”ë¼ë„ ì¼ë‹¨ ì—¬ê¸´ ì•ˆë¼ ì•„ë‹ˆ ìš´ì „í•˜ê³  ì§€ë‚˜ê°€ëŠ”ë° ì¿ íŒ¡ ë¬¼ë¥˜ì„¼í„°ê°€ ì‡ë”ë¼ë„ ì œì£¼ì‹œ ìª½ì— ê·¸ ë¡œì¼“ë°°ì†¡ ë§êµ¬ ë‹¤ë¥¸ íƒë°°ë¡œ ì²œì²œíˆë¼ë„ ì™€? á„€á„…ì„....? #@ì‹œìŠ¤í…œ#ì‚¬ì§„#ì‚¬ì§„# ë‚˜ë„ ë°¥ ë¬´ì•µ ì•¼ ì œì£¼ë„ëŠ” ë¡œì¼“ë°°ì†¡ê°€ëŠ¥í•´? ê¸€ì„ ë³´ê³ ì˜¬ê²Œ ì–´ì œ ìš´ì „í• ë•Œ ë³´ë‹ˆê¹ ë¡œì¼“ ë°°ì•µ ì•¼ ì œì£¼ë„ëŠ” ë¡œì¼“ë°°ì†¡ê°€ëŠ¥í•´? ê¸€ì„ ë³´ê³ ì˜¬ê²Œ ì–´ì œ ìš´ì „í• ë•Œ ë³´ë‹ˆê¹ ë¡œì¼“ í”„ë ˆì‹œ ì‡ë“œë¼ #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ì•„ê¹Œ ë³´ë‹ˆê¹ ë¡œì¼“ í”„ë ˆì‹œ ì‡ë“œë¼ #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ë‚˜ë„ ë°¥ ë¬´ê±°ìš” í˜¸ì•µ ì•¼ ì œì£¼ë„ëŠ” ë¡œì¼“ë°°ì†¡ê°€ëŠ¥í•´? #@ì‹œìŠ¤í…œ#ì‚¬ì§„# ë‚˜ë„ ë°¥ ë¬´ê±°ìš” í˜¸ì•µ ì•¼ ì œì£¼ë„ëŠ” ë¡œì¼“ë°°ì†¡ê°€ëŠ¥í•´? ê¸€ì„ ë³´ê³ ì˜¬ê²Œ ì–´ì œ ìš´ì „í• ë•Œ ë³´ë‹ˆë”´ ì¿ íŒ¡ ë¨¸ ì‡ê¸´ í•˜ë˜ë° ìš´ì „í•˜ëŠ”ë° '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "# KOBART ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "model_name = \"skt/kobart\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# ìš”ì•½í•  ë¬¸ì¥ ì…ë ¥\n",
        "input_text = \"í•œêµ­ì–´ ë¬¸ì¥ì„ ìš”ì•½í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\"\n",
        "\n",
        "# ë¬¸ì¥ì„ í† í°í™”í•˜ê³  ì…ë ¥ ì¸ì½”ë”©\n",
        "inputs = tokenizer(input_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "\n",
        "# ëª¨ë¸ì— ì…ë ¥ ì „ë‹¬í•˜ì—¬ ìš”ì•½ ìƒì„±\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=100, early_stopping=True)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# ìš”ì•½ ì¶œë ¥\n",
        "print(\"Input:\", input_text)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "JRGCWeIqxpfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "pfC9crP5erZG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}