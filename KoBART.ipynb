{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWc/Yz4yQwrMp05QsJGxj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaejuna/SpeedWagon/blob/main/KoBART.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/SKT-AI/KoBART#how-to-install"
      ],
      "metadata": {
        "id": "yArg9R8qAWTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX_UY-bVhE3D",
        "outputId": "9687352c-7ca3-4324-959e-acf4233551b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbCDWH-c2sbx",
        "outputId": "78553b39-37d2-4bd2-84ec-860f354ee29d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "import tensorflow"
      ],
      "metadata": {
        "id": "1EhP2tFGikkK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SKT-AI/KoBART.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNmGuzVEgSNx",
        "outputId": "b0b62d51-28a0-4388-c05c-33868ac6089e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoBART'...\n",
            "remote: Enumerating objects: 331, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 331 (delta 13), reused 14 (delta 13), pack-reused 303\u001b[K\n",
            "Receiving objects: 100% (331/331), 8.24 MiB | 16.51 MiB/s, done.\n",
            "Resolving deltas: 100% (176/176), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VzZHC3tng3gD",
        "outputId": "2aa9e62a-1a78-4727-fc82-a13e1c4701b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd KoBART"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ1ehGAcgcsp",
        "outputId": "4484587b-c976-4185-e92c-d011c596c2a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBART\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UA5RtWXakMQW",
        "outputId": "f584d66b-1e12-465d-8be5-21ef6396effa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg-u1CLUxRU4",
        "outputId": "eeaab512-2336-4b2a-ac21-537f5f0cbc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/nvfuser/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.0.1+cu118.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==1.7.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DnJe3cCxSbw",
        "outputId": "71f46468-f6f5-4c2e-c7ff-db5a42fd6141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PfLStjGgZlK",
        "outputId": "130ed515-4da8-489f-f59b-cb86a1be0ffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.26.140)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
            "Collecting pytorch-lightning==1.2.1 (from -r requirements.txt (line 3))\n",
            "  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m814.2/814.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAVaF2Ys2nuA",
        "outputId": "41c53d74-006f-4f4d-c4f7-18c9407e76e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.140-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.140 (from boto3)\n",
            "  Downloading botocore-1.29.140-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.140->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.140->boto3) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.140->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.140 botocore-1.29.140 jmespath-1.0.1 s3transfer-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbsqHpajTa4G",
        "outputId": "f40b74a9-baf2-415a-953a-68c4c5923295"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kobart import get_kobart_tokenizer\n",
        "kobart_tokenizer = get_kobart_tokenizer()\n",
        "kobart_tokenizer.tokenize(\"안녕하세요. 한국어 BART 입니다.🤣:)l^o\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ifOrRoATm0",
        "outputId": "7c477e16-cf19-49cf-ee13-53cedd52613f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBART/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁안녕하', '세요.', '▁한국어', '▁B', 'A', 'R', 'T', '▁입', '니다.', '🤣', ':)', 'l^o']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/BOAZ_miniProject2/train.csv')\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/BOAZ_miniProject2/valid.csv')"
      ],
      "metadata": {
        "id": "3Vn0Bp9rjdfA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import re\n",
        "import torch\n",
        "from rouge import Rouge\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "DTeytsnnTmNV",
        "outputId": "e5ee2602-bcf3-4ca7-aa8e-5253fcd97f7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-15e55e1a57b5>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRouge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m from transformers import (\n\u001b[1;32m     12\u001b[0m     \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame을 Dataset으로 전환\n",
        "import datasets\n",
        "train_data = Dataset.from_pandas(train_df) \n",
        "val_data = Dataset.from_pandas(val_df)\n",
        "test_samples = Dataset.from_pandas(val_df)\n",
        "\n",
        "print(train_data)\n",
        "print(val_data)\n",
        "print(test_samples)"
      ],
      "metadata": {
        "id": "LvoIbVRDtYPU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "ab708bc4-3f12-465a-9685-83c032a2e51e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ba57b633e5a6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DataFrame을 Dataset으로 전환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "kobart_tokenizer = get_kobart_tokenizer()\n",
        "model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model())\n",
        "text = \"\"\"\n",
        "1일 오후 9시까지 최소 20만3220명이 코로나19에 신규 확진됐다. 또다시 동시간대 최다 기록으로, 사상 처음 20만명대에 진입했다.\n",
        "방역 당국과 서울시 등 각 지방자치단체에 따르면 이날 0시부터 오후 9시까지 전국 신규 확진자는 총 20만3220명으로 집계됐다.\n",
        "국내 신규 확진자 수가 20만명대를 넘어선 것은 이번이 처음이다.\n",
        "동시간대 최다 기록은 지난 23일 오후 9시 기준 16만1389명이었는데, 이를 무려 4만1831명이나 웃돌았다. 전날 같은 시간 기록한 13만3481명보다도 6만9739명 많다.\n",
        "확진자 폭증은 3시간 전인 오후 6시 집계에서도 예견됐다.\n",
        "오후 6시까지 최소 17만8603명이 신규 확진돼 동시간대 최다 기록(24일 13만8419명)을 갈아치운 데 이어 이미 직전 0시 기준 역대 최다 기록도 넘어섰다. 역대 최다 기록은 지난 23일 0시 기준 17만1451명이었다.\n",
        "17개 지자체별로 보면 서울 4만6938명, 경기 6만7322명, 인천 1만985명 등 수도권이 12만5245명으로 전체의 61.6%를 차지했다. 서울과 경기는 모두 동시간대 기준 최다로, 처음으로 각각 4만명과 6만명을 넘어섰다.\n",
        "비수도권에서는 7만7975명(38.3%)이 발생했다. 제주를 제외한 나머지 지역에서 모두 동시간대 최다를 새로 썼다.\n",
        "부산 1만890명, 경남 9909명, 대구 6900명, 경북 6977명, 충남 5900명, 대전 5292명, 전북 5150명, 울산 5141명, 광주 5130명, 전남 4996명, 강원 4932명, 충북 3845명, 제주 1513명, 세종 1400명이다.\n",
        "집계를 마감하는 자정까지 시간이 남아있는 만큼 2일 0시 기준으로 발표될 신규 확진자 수는 이보다 더 늘어날 수 있다. 이에 따라 최종 집계되는 확진자 수는 21만명 안팎을 기록할 수 있을 전망이다.\n",
        "한편 전날 하루 선별진료소에서 이뤄진 검사는 70만8763건으로 검사 양성률은 40.5%다. 양성률이 40%를 넘은 것은 이번이 처음이다. 확산세가 계속 거세질 수 있다는 얘기다.\n",
        "이날 0시 기준 신규 확진자는 13만8993명이었다. 이틀 연속 13만명대를 이어갔다.\n",
        "\"\"\"\n",
        "text = text.replace('\\n', ' ')\n",
        "\n",
        "inputs = kobart_tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "raw_input_ids = kobart_tokenizer.encode(text)\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "aTR4MyaVdvP2",
        "outputId": "bdb9a179-39f0-4399-b4be-3114dcb2f4c6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/KoBART/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
            "/content/KoBART/.cache/kobart_base_cased_ff4bda5738.zip[██████████████████████████████████████████████████]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"다.다.다.다.다.다.다. 최소 20만3220명이 코로나19에 신규 확진됐다. 또다시 동시간대 최다 기록으로, 사상 처음 20만명대에 진입했다. 방역 당국과 서울시 등 각 지방자치단체에 따르면 이날 0시부터 오후 9시까지 전국 신규 확진자는 총 20만3220명으로 집계됐다. 국내 신규 확진자 수가 20만명대를 넘어선 것은 이번이 처음이다. 동시간대 최다 기록은 지난 23일 오후 9시 기준 16만1389명이었는데, 이를 무려 4만1831명이나 웃돌았다. 전날 같은 시간 기록한 13만3481명보다도 6만9739명이나 웃돌았다. 전날 같은 시간 기록한 13만3481명보다도 6만9739명 많다. 확진자 폭증은 3시간 전인 오후 6시 집계에서도 예견됐다. 오후 6시까지 최소 17만8603명이 신규 확진돼 동시간대 최다 기록(24일 13만8419명)을 갈아치운 데 이어 이미 직전 0시 기준 역대 최다 기록도 넘어섰다. 역대 최다 기록은 지난 23일 0시 기준 17만1451명이었다. 17개 지자체별로 보면 서울 4만6938명, 경기 6만7322명, 인천 1만985명 등 수도권이 12만5245명으로 전체의 61.6%를 차지했다. 서울과 경기는 모두 동시간대 기준 최다로, 처음으로 각각 4만명과 6만명을 넘어섰다. 비수도권에서는 7만7975명(38.3%)이 발생했다. 제주를 제외한 나머지 지역에서 모두 동시간대 최다를 새로 썼다. 부산 1만890명, 경남 9909명, 대구 6900명, 경북 6977명, 충남 5900명, 충남 5900명, 대전 5292명, 전북 5150명, 울산 5141명, 대구 5130명, 경북 4996명, 전남 4996명, 강원 4932명, 광주 3845명, 전남 4996명, 강원 4932명, 충북 3845명, 제주 1513명, 세종 1400명이다. 집계를 마감하는 자정까지 시간이 남아있는 만큼 2일 0시 기준으로 발표될 신규 확진자 수는 이보다 더 늘어날 수 있다. 이에 따라 최종 집계되는 확진자 수는 21만명 안팎을 기록할 수 있을 전망이다. 한편 전날 하루 선별진료소에서 이뤄진 검사는 70만8763건으로 검사 양성률은 40.5%다. 양성률이 40%를 넘은 것은 이번이 처음이다. 확산세가 계속 거세질 수 있다는 얘기다. 이날 0시 기준 신규 확진자는 13만8993명이었다. 이틀 연속 13만명대를 이어갔, 이틀 연속 13만명대를 이어갔'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.iloc[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "SFLkCUtmj8Ph",
        "outputId": "c6e4b699-59ee-4334-b54f-f14887f8bec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'웃긴게 20년동안... 바로 옆 가게 주차장에서 같이 그 감자탕집 주차도 했었는데 그 가게에서 이제 못대게해서; 졸지에...감자탕집 주차 없어짐 ㅜㅜ 헐 의상하는 일 있었나? 뭐..아무래도 그 감자탕집이 장사 잘되니까 ㅋㅋㅋㅋㅋㅋㅋ 배아파서.. 아.. 그렇다고 감자탕집을 안간다해서 그 가게는 안갈거같은데; 거기는..뭔 능이버섯 오리전골? 뭐 이런거라 대중적이진 않잖아 아 점심으로 투머치..'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "kobart_tokenizer = get_kobart_tokenizer()\n",
        "model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtAaQUCAlxi5",
        "outputId": "0880b411-f0bc-4624-f1e3-11dc016d392b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/KoBART/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n",
            "/content/KoBART/.cache/kobart_base_cased_ff4bda5738.zip[██████████████████████████████████████████████████]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs = kobart_tokenizer(train.iloc[0,0], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "text = train.iloc[0,0]\n",
        "raw_input_ids = kobart_tokenizer.encode(text)\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "1-YiS1LUj3J4",
        "outputId": "f5e7fcd9-39b8-4cc0-b9da-df752d6fe03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'웃긴게 20년동안... 바로 옆 가게 주차장에서 같이 그 감자탕집 주차도 했었는데 그 가게에서 이제 못대게해서; 졸지에... 졸지에...감자탕집 주차 없어짐  헐 의상하는 일 있었나? 뭐..아무래도 그 감자탕집이 장사 잘되니까 ᄏᄏᄏᄏᄏᄏᄏᄏᄏ 그렇다고 감자탕집을 안간다해서 그 가게는 안갈거같은데; 거기는..뭔 아 옆 가게 주차장에서 같이 그 감자탕집 주차도 했었는데 같이 그 감자탕집 주차도 했었는데 그 가게에서 이제 못대게해서; 졸지에... 감자탕집 주차 없어게해서; 졸지에...감자탕집 주차 없어짐  헐 의상하는 일 있었나? 뭐..아무래도 그 감자탕집이 장사 잘되니까 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ 배아파서.. 아.. 그렇다고 감자탕집을 안간다해서 그 가게는 안갈거같은데; 거기는..뭔 능이버섯 오리전골? 뭐 이런거라 대중적이진 않잖아 아 점심으로 투머치.. 아 점심으로 투머치.. 아 점심으로 투머치.... 아머치.. 아음..감자탕집 장사 잘되니까 장사 잘되니까 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ 배아파서.. 아 점심으로 투머치....뭔 능이버섯 오리전골? 뭐 이런거라 대중적이진 않잖아 아 점심으로 투머치...... 점심으로 투머치............감자탕집 주차 없어짐....감자탕집 주차 없어짐  헐 의상하는 일 있었나? 뭐..아무래도 그 감자탕집이 장사 잘되니까 ᄏᄏᄏᄏᄏᄏᄏᄏᄏ 배아파서.. 아.. 그렇다고 감자탕집을 안간다해서 그 가게는 안갈거같은데.. 아.. 그렇다고 감자탕집을 안간다해서 그 가게는 안갈거같은데; 거기는..뭔 능이버섯 오리전골? 뭐 이런거라 대중적이진 않잖아 아'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs = kobart_tokenizer(train.iloc[0,0], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "text = train.iloc[1,0]\n",
        "raw_input_ids = kobart_tokenizer.encode(text)\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "cReBfdQLqOph",
        "outputId": "69c130d7-1660-4e1b-acc0-a934488e499e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'아까 보니깐 로켓 프레시 잇드라 #@시스템#사진# 나도 밥 무거요 호앵 야 제주도는 로켓배송가능해? 글쎄 보고올게 어제 운전할때 보니딴 쿠팡 머 잇긴 하던데 운전하는데 폰을 왜 보나 보니 어제 운전할때 보니딴 쿠팡 머 잇긴 하던데 운전하는데 폰을 왜 보나 보니 #@시스템#사진# 일단 여긴 안돼 아니 운전하고 지나가는데 쿠팡 물류센터가 잇더라도 제주시 쪽에 그 로켓배송 말구 다른 택배로 천천히라도 와? ᄀᄅ쎄....??????? 나도 밥 무거요 호앵 야 제주도는 로켓배송가능해? 글쎄 보고올게 어제 운전할때 보니딴 쿠팡 머 잇긴 하던데 운전긴 하던데 운전하는데 폰을 왜 보나 보니 #@시스템#사진# 일단 여긴 안돼 아니 쿠팡 머 잇긴 하던데 운전하는데 폰을 왜 보나 보니 #@시스템#사진# 일단 여긴 안돼 아니 운전하고 지나가는데 쿠팡 물류센터가 잇더라도 제주시 쪽에 그 로켓배송 말구 다른 택배로 천천히라도 와? ᄀᄅ쎄....?? 천천히라도 와? ᄀᄅ쎄....?????? ᄀᄅ쎄....???? 나도 밥 무거요 호앵 야 제주도는 로켓배송가능해? 글쎄 보고올게 어제 운전할때 보니딴 쿠팡 머 잇긴 하던데 운전하는데 폰을 왜 보나 보니 #@시스템#사진#사진# 일단 여긴 안돼 아니 운전하고 지나가는데 쿠팡 물류센터가 잇더라도 일단 여긴 안돼 아니 운전하고 지나가는데 쿠팡 물류센터가 잇더라도 제주시 쪽에 그 로켓배송 말구 다른 택배로 천천히라도 와? ᄀᄅ쎄....? #@시스템#사진#사진# 나도 밥 무앵 야 제주도는 로켓배송가능해? 글쎄 보고올게 어제 운전할때 보니깐 로켓 배앵 야 제주도는 로켓배송가능해? 글쎄 보고올게 어제 운전할때 보니깐 로켓 프레시 잇드라 #@시스템#사진# 아까 보니깐 로켓 프레시 잇드라 #@시스템#사진# 나도 밥 무거요 호앵 야 제주도는 로켓배송가능해? #@시스템#사진# 나도 밥 무거요 호앵 야 제주도는 로켓배송가능해? 글쎄 보고올게 어제 운전할때 보니딴 쿠팡 머 잇긴 하던데 운전하는데 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "# KOBART 모델과 토크나이저 로드\n",
        "model_name = \"skt/kobart\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# 요약할 문장 입력\n",
        "input_text = \"한국어 문장을 요약하는 예제입니다.\"\n",
        "\n",
        "# 문장을 토큰화하고 입력 인코딩\n",
        "inputs = tokenizer(input_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "\n",
        "# 모델에 입력 전달하여 요약 생성\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=100, early_stopping=True)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# 요약 출력\n",
        "print(\"Input:\", input_text)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "JRGCWeIqxpfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "pfC9crP5erZG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}