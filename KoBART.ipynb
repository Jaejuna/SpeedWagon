{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaejuna/SpeedWagon/blob/main/KoBART.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yArg9R8qAWTn"
      },
      "source": [
        "https://github.com/SKT-AI/KoBART#how-to-install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX_UY-bVhE3D",
        "outputId": "fc05e8a1-4846-4952-9cbb-1d57effe340c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbCDWH-c2sbx",
        "outputId": "f08e8f8b-0ad1-484c-b502-aaddf18194bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Rouge) (1.16.0)\n",
            "Installing collected packages: Rouge\n",
            "Successfully installed Rouge-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.142-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.142 (from boto3)\n",
            "  Downloading botocore-1.29.142-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.142->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.142->boto3) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.142->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.142 botocore-1.29.142 jmespath-1.0.1 s3transfer-0.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install Rouge\n",
        "!pip install boto3\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1EhP2tFGikkK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNmGuzVEgSNx",
        "outputId": "8cc092f6-0988-404d-aaab-fcfe4e9bb89a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoBART'...\n",
            "remote: Enumerating objects: 331, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 331 (delta 13), reused 14 (delta 13), pack-reused 303\u001b[K\n",
            "Receiving objects: 100% (331/331), 8.24 MiB | 13.52 MiB/s, done.\n",
            "Resolving deltas: 100% (176/176), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SKT-AI/KoBART.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VzZHC3tng3gD",
        "outputId": "a76672e1-887a-42cb-dc02-92c053a17623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ1ehGAcgcsp",
        "outputId": "c951db39-494d-41ba-b127-1021a2118bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBART\n"
          ]
        }
      ],
      "source": [
        "%cd KoBART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UA5RtWXakMQW",
        "outputId": "f584d66b-1e12-465d-8be5-21ef6396effa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.1+cu118'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg-u1CLUxRU4",
        "outputId": "eeaab512-2336-4b2a-ac21-537f5f0cbc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/nvfuser/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.0.1+cu118.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "pip uninstall torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DnJe3cCxSbw",
        "outputId": "71f46468-f6f5-4c2e-c7ff-db5a42fd6141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install torch==1.7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PfLStjGgZlK",
        "outputId": "741dcca8-bde1-4377-e3da-91d4d36f29b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.26.142)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
            "Collecting pytorch-lightning==1.2.1 (from -r requirements.txt (line 3))\n",
            "  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m814.2/814.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32ifOrRoATm0",
        "outputId": "cd172a7b-29b8-401c-98c7-4c8e9be33087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBART/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['â–ì•ˆë…•í•˜', 'ì„¸ìš”.', 'â–í•œêµ­ì–´', 'â–B', 'A', 'R', 'T', 'â–ì…', 'ë‹ˆë‹¤.', 'ğŸ¤£', ':)', 'l^o']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from kobart import get_kobart_tokenizer\n",
        "kobart_tokenizer = get_kobart_tokenizer()\n",
        "kobart_tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ BART ì…ë‹ˆë‹¤.ğŸ¤£:)l^o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3Vn0Bp9rjdfA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/BOAZ_miniProject2/train_new.csv')\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/BOAZ_miniProject2/valid_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV70vbke_6jw",
        "outputId": "c9376f0a-6598-4fc6-b662-d2f4f1ec7c80"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27993, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMQBo6Gt_8H1",
        "outputId": "9f7564db-5d35-41d0-aa66-8ee32e3cd1ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3496, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.iloc[:10000,:]"
      ],
      "metadata": {
        "id": "j0UFIkoR_98y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVsJ-5SoACE9",
        "outputId": "23a60a58-19a8-402b-fe06-d08ca165d2fc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DTeytsnnTmNV"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import re\n",
        "import torch\n",
        "from rouge import Rouge\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvoIbVRDtYPU",
        "outputId": "16db97a2-8b71-499a-bcfa-dda7bc3ff772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['Text', 'Summary', 'Topic'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Text', 'Summary', 'Topic'],\n",
            "    num_rows: 3496\n",
            "})\n",
            "Dataset({\n",
            "    features: ['Text', 'Summary', 'Topic'],\n",
            "    num_rows: 3496\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# DataFrameì„ Datasetìœ¼ë¡œ ì „í™˜\n",
        "import datasets\n",
        "from datasets import Dataset\n",
        "train_data = Dataset.from_pandas(train_df) \n",
        "valid_data = Dataset.from_pandas(valid_df)\n",
        "test_samples = Dataset.from_pandas(valid_df)\n",
        "\n",
        "print(train_data)\n",
        "print(valid_data)\n",
        "print(test_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC40ZbhlYNmA",
        "outputId": "14f21117-15ec-478f-f93d-b1e9b531b15e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BOAZ_miniProject2/kobart_base_tokenizer_cased_cf74400bce.zip[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/KoBART/.cache/kobart_base_cased_ff4bda5738.zip\n"
          ]
        }
      ],
      "source": [
        "from transformers import BartForConditionalGeneration\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "\n",
        "model_checkpoints = '/content/drive/MyDrive/BOAZ_miniProject2'\n",
        "kobart_tokenizer = get_kobart_tokenizer(model_checkpoints)\n",
        "model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model(model_checkpoints))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aTR4MyaVdvP2",
        "outputId": "9a53498a-e001-412f-ab13-6b53b9ab3f5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'í™•ì§„ìê°€ ê¸‰ì¦í•˜ê³  ìˆë‹¤.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# ì˜ˆì‹œ í…ìŠ¤íŠ¸\n",
        "text = \"\"\"\n",
        "1ì¼ ì˜¤í›„ 9ì‹œê¹Œì§€ ìµœì†Œ 20ë§Œ3220ëª…ì´ ì½”ë¡œë‚˜19ì— ì‹ ê·œ í™•ì§„ëë‹¤. ë˜ë‹¤ì‹œ ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡ìœ¼ë¡œ, ì‚¬ìƒ ì²˜ìŒ 20ë§Œëª…ëŒ€ì— ì§„ì…í–ˆë‹¤.\n",
        "ë°©ì—­ ë‹¹êµ­ê³¼ ì„œìš¸ì‹œ ë“± ê° ì§€ë°©ìì¹˜ë‹¨ì²´ì— ë”°ë¥´ë©´ ì´ë‚  0ì‹œë¶€í„° ì˜¤í›„ 9ì‹œê¹Œì§€ ì „êµ­ ì‹ ê·œ í™•ì§„ìëŠ” ì´ 20ë§Œ3220ëª…ìœ¼ë¡œ ì§‘ê³„ëë‹¤.\n",
        "êµ­ë‚´ ì‹ ê·œ í™•ì§„ì ìˆ˜ê°€ 20ë§Œëª…ëŒ€ë¥¼ ë„˜ì–´ì„  ê²ƒì€ ì´ë²ˆì´ ì²˜ìŒì´ë‹¤.\n",
        "ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡ì€ ì§€ë‚œ 23ì¼ ì˜¤í›„ 9ì‹œ ê¸°ì¤€ 16ë§Œ1389ëª…ì´ì—ˆëŠ”ë°, ì´ë¥¼ ë¬´ë ¤ 4ë§Œ1831ëª…ì´ë‚˜ ì›ƒëŒì•˜ë‹¤. ì „ë‚  ê°™ì€ ì‹œê°„ ê¸°ë¡í•œ 13ë§Œ3481ëª…ë³´ë‹¤ë„ 6ë§Œ9739ëª… ë§ë‹¤.\n",
        "í™•ì§„ì í­ì¦ì€ 3ì‹œê°„ ì „ì¸ ì˜¤í›„ 6ì‹œ ì§‘ê³„ì—ì„œë„ ì˜ˆê²¬ëë‹¤.\n",
        "ì˜¤í›„ 6ì‹œê¹Œì§€ ìµœì†Œ 17ë§Œ8603ëª…ì´ ì‹ ê·œ í™•ì§„ë¼ ë™ì‹œê°„ëŒ€ ìµœë‹¤ ê¸°ë¡(24ì¼ 13ë§Œ8419ëª…)ì„ ê°ˆì•„ì¹˜ìš´ ë° ì´ì–´ ì´ë¯¸ ì§ì „ 0ì‹œ ê¸°ì¤€ ì—­ëŒ€ ìµœë‹¤ ê¸°ë¡ë„ ë„˜ì–´ì„°ë‹¤. ì—­ëŒ€ ìµœë‹¤ ê¸°ë¡ì€ ì§€ë‚œ 23ì¼ 0ì‹œ ê¸°ì¤€ 17ë§Œ1451ëª…ì´ì—ˆë‹¤.\n",
        "17ê°œ ì§€ìì²´ë³„ë¡œ ë³´ë©´ ì„œìš¸ 4ë§Œ6938ëª…, ê²½ê¸° 6ë§Œ7322ëª…, ì¸ì²œ 1ë§Œ985ëª… ë“± ìˆ˜ë„ê¶Œì´ 12ë§Œ5245ëª…ìœ¼ë¡œ ì „ì²´ì˜ 61.6%ë¥¼ ì°¨ì§€í–ˆë‹¤. ì„œìš¸ê³¼ ê²½ê¸°ëŠ” ëª¨ë‘ ë™ì‹œê°„ëŒ€ ê¸°ì¤€ ìµœë‹¤ë¡œ, ì²˜ìŒìœ¼ë¡œ ê°ê° 4ë§Œëª…ê³¼ 6ë§Œëª…ì„ ë„˜ì–´ì„°ë‹¤.\n",
        "ë¹„ìˆ˜ë„ê¶Œì—ì„œëŠ” 7ë§Œ7975ëª…(38.3%)ì´ ë°œìƒí–ˆë‹¤. ì œì£¼ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì§€ì—­ì—ì„œ ëª¨ë‘ ë™ì‹œê°„ëŒ€ ìµœë‹¤ë¥¼ ìƒˆë¡œ ì¼ë‹¤.\n",
        "ë¶€ì‚° 1ë§Œ890ëª…, ê²½ë‚¨ 9909ëª…, ëŒ€êµ¬ 6900ëª…, ê²½ë¶ 6977ëª…, ì¶©ë‚¨ 5900ëª…, ëŒ€ì „ 5292ëª…, ì „ë¶ 5150ëª…, ìš¸ì‚° 5141ëª…, ê´‘ì£¼ 5130ëª…, ì „ë‚¨ 4996ëª…, ê°•ì› 4932ëª…, ì¶©ë¶ 3845ëª…, ì œì£¼ 1513ëª…, ì„¸ì¢… 1400ëª…ì´ë‹¤.\n",
        "ì§‘ê³„ë¥¼ ë§ˆê°í•˜ëŠ” ìì •ê¹Œì§€ ì‹œê°„ì´ ë‚¨ì•„ìˆëŠ” ë§Œí¼ 2ì¼ 0ì‹œ ê¸°ì¤€ìœ¼ë¡œ ë°œí‘œë  ì‹ ê·œ í™•ì§„ì ìˆ˜ëŠ” ì´ë³´ë‹¤ ë” ëŠ˜ì–´ë‚  ìˆ˜ ìˆë‹¤. ì´ì— ë”°ë¼ ìµœì¢… ì§‘ê³„ë˜ëŠ” í™•ì§„ì ìˆ˜ëŠ” 21ë§Œëª… ì•ˆíŒì„ ê¸°ë¡í•  ìˆ˜ ìˆì„ ì „ë§ì´ë‹¤.\n",
        "í•œí¸ ì „ë‚  í•˜ë£¨ ì„ ë³„ì§„ë£Œì†Œì—ì„œ ì´ë¤„ì§„ ê²€ì‚¬ëŠ” 70ë§Œ8763ê±´ìœ¼ë¡œ ê²€ì‚¬ ì–‘ì„±ë¥ ì€ 40.5%ë‹¤. ì–‘ì„±ë¥ ì´ 40%ë¥¼ ë„˜ì€ ê²ƒì€ ì´ë²ˆì´ ì²˜ìŒì´ë‹¤. í™•ì‚°ì„¸ê°€ ê³„ì† ê±°ì„¸ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì–˜ê¸°ë‹¤.\n",
        "ì´ë‚  0ì‹œ ê¸°ì¤€ ì‹ ê·œ í™•ì§„ìëŠ” 13ë§Œ8993ëª…ì´ì—ˆë‹¤. ì´í‹€ ì—°ì† 13ë§Œëª…ëŒ€ë¥¼ ì´ì–´ê°”ë‹¤.\n",
        "\"\"\"\n",
        "text = text.replace('\\n', ' ')\n",
        "\n",
        "raw_input_ids = kobart_tokenizer.encode(text)\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df.iloc[3495,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J-FhFhreQpCk",
        "outputId": "d839afbe-5a59-4b8c-e48d-da5ab46745dd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì•„ ê³µì—°ëŠ¦ê² ë‹¤ ì§‘ë“¤ë ¤ì„œ ì§ë†“ê³  ë¹¨ë¦¬ë‚˜ì™“ëŠ”ë° ã…  í—‰ ë¹¨ë¦¬ê°€ì•¼ì§€ë­ã… ã…  ë‚˜ëŠ” ì¤€ë¹„ì¤‘ ê·¸ë ‡êµ¬ë§Œ í™”ì¥ì¤‘ì´ì˜ˆìš© #@ì´ë¦„#ì´ ì˜¤ëŠ˜ ì—´ì‹¬íˆê¾¸ë¯¸ë‚˜ ì§€ê¸ˆëŠ¦ì–´ì„œ ê±°ì˜ë‹¤ì™€ê°€ì§€ê³  íƒì‹œíƒ”ì–´'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_input_ids = kobart_tokenizer.encode(valid_df.iloc[3495,0])\n",
        "input_ids = [kobart_tokenizer.bos_token_id] + raw_input_ids + [kobart_tokenizer.eos_token_id]\n",
        "\n",
        "summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n",
        "kobart_tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BYzysy4KQT-N",
        "outputId": "d958895d-d2ab-41b6-c897-1fd2e8b4dbdb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ê³µì—°ì¤‘ë ¤ì„œ ë¹¨ë¦¬ë‚˜ì™”ëŠ”ë° ì§‘ë“¤ë ¤ì„œ ì§ë†“ê³  ë¹¨ë¦¬ë‚˜ì™”ëŠ”ë° í™”ì¥ì¤‘ì´ ë˜ì—ˆë‹¤.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0Otj6uuchEsn"
      },
      "outputs": [],
      "source": [
        "# í›ˆë ¨ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for data in train_data:\n",
        "    encoded_data = kobart_tokenizer.encode_plus(\n",
        "        data[\"Text\"],\n",
        "        max_length=300,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids.append(encoded_data[\"input_ids\"])\n",
        "    attention_masks.append(encoded_data[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_ids = []\n",
        "\n",
        "for data in train_data:\n",
        "    encoded_data = kobart_tokenizer.encode_plus(\n",
        "        data[\"Summary\"],\n",
        "        max_length=300,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    output_ids.append(encoded_data[\"input_ids\"])\n",
        "    attention_masks.append(encoded_data[\"attention_mask\"])"
      ],
      "metadata": {
        "id": "vv7qsdaU8V5K"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0ipkQasyh79O"
      },
      "outputs": [],
      "source": [
        "# í›ˆë ¨ ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOVfC4aO4TYr",
        "outputId": "f57d2f12-514c-4b53-9668-3b9cef5e3574"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhxq8EvTh5hc"
      },
      "outputs": [],
      "source": [
        "# í›ˆë ¨\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(len(input_ids)):\n",
        "        inputs = {\n",
        "            \"input_ids\": input_ids[i].to(device),\n",
        "            \"attention_mask\": attention_masks[i].to(device),\n",
        "            \"labels\": output_ids[i].to(device)\n",
        "        }\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if (i % 1000 == 0):\n",
        "          print(f\"{i}ë²ˆì§¸ complete\")\n",
        "\n",
        "    average_loss = total_loss / len(input_ids)\n",
        "    print(f\"Epoch {epoch+1} / {num_epochs} - Average Loss: {average_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì €ì¥\n",
        "import joblib \n",
        "joblib.dump(model, '/content/drive/MyDrive/BOAZ_miniProject2/kobart1.pkl')"
      ],
      "metadata": {
        "id": "8kWTdrtXo__c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a47b35-e8ff-418a-d591-e864abd352c2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/BOAZ_miniProject2/kobart1.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = joblib.load(\"/content/drive/MyDrive/BOAZ_miniProject2/kobart1.pkl\")"
      ],
      "metadata": {
        "id": "rL1loLICpdkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
        "\n",
        "# ìš”ì•½ ë° ROUGE ì ìˆ˜ ë¹„êµ\n",
        "references = []\n",
        "summaries = []\n",
        "\n",
        "for data in valid_data:\n",
        "    # ì…ë ¥ ë¬¸ì¥ ë° ìš”ì•½ ëŒ€ìƒ ë¬¸ì¥ ê°€ì ¸ì˜¤ê¸°\n",
        "    input_text = data[\"Text\"]\n",
        "    target_summary = data[\"Summary\"]\n",
        "\n",
        "    # KoBARTì— ì…ë ¥ ë¬¸ì¥ í† í¬ë‚˜ì´ì§•\n",
        "    input_ids = kobart_tokenizer.encode(input_text, truncation=True, max_length=300, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    # KoBARTë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ ìƒì„±\n",
        "    summary_ids = model.generate(input_ids=input_ids.to(model.device), max_length=150, num_beams=4, early_stopping=True)\n",
        "    summary = kobart_tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥\n",
        "    references.append([target_summary])\n",
        "    summaries.append(summary)\n",
        "\n",
        "# ROUGE ì ìˆ˜ ê³„ì‚°\n",
        "rouge_scores = corpus_bleu(references, summaries, smoothing_function=SmoothingFunction().method4)\n",
        "print(\"ROUGE Scores:\")\n",
        "print(f\"ROUGE-1: {rouge_scores[0] * 100:.2f}\")\n",
        "print(f\"ROUGE-2: {rouge_scores[1] * 100:.2f}\")\n",
        "print(f\"ROUGE-L: {rouge_scores[2] * 100:.2f}\")"
      ],
      "metadata": {
        "id": "nECSXTlr_MQS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "a67ada61-dc62-450f-bff1-c2ad1c551ce1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b8c49ce166b8>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# KoBARTë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ ìƒì„±\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msummary_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkobart_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m             )\n\u001b[1;32m   1603\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1605\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2903\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 )\n\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 )\n\u001b[1;32m   1117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1119\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# reuse k, v, self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7v_XCeZnyce",
        "outputId": "e5e7f889-f861-4af8-f514-299f2d10a688"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ë‹‰ì¥ê°“ë‹¤ì˜¨ ë‚  íšŒì‚¬ ì•ˆ ê°€ê³  ì§‘ì— ëª» ê°”ë‹¤.',\n",
              " 'íŒêµì—ì„œ ë˜ ë§‰í˜”ë‹¤.',\n",
              " 'ë²„ìŠ¤ ê¸°ë‹¤ë¦¬êµ¬ì´ìª„ ë²„ìŠ¤ê°€ë„ˆë¬´ ëŠ¦ê²Œ ì™”ë‹¤.',\n",
              " 'ì•„ì–‘êµê¹Œì§€ ë§‰íŒë‹¤.',\n",
              " 'ì´ë”° ê·¸ì¹œë‹¤ê³  í•œë‹¤.',\n",
              " 'ìœ ì—˜ ìœ ì—˜ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.',\n",
              " 'ì´ë²ˆ ì¶”ìœ¨ ëŒì•„ë‹¤ë‹ˆê³ í•  ë•Œ ë³„ë¡œ ì•ˆ ì¶”ìš´ëŒ€ í•œíŒŒë©´ ê°€ê¸° ì‹«ë‹¤.',\n",
              " '3ë²ˆì§¸í‹€ë ·ì–´ë ˆì´(í‹€ë ·ì–´ë ˆì´)ë¼ê³  í•œë‹¤.',\n",
              " 'ì¹´ë“œ ë§ˆë‹ˆ(ë§ˆë‹ˆ) ì¼ëŠ”ë° ëˆì•„ê»´ì•¼ í•œë‹¤.',\n",
              " 'ì¹´í˜ íƒë°°ëŠ” ë‹¤ ë°›ì•˜ë‹¤.',\n",
              " 'ì£¼ë§ì—ë„ ì‹¬í•˜ë©´ ì‚°ì±…ë„ ëª»í•˜ê² ë‹¤.',\n",
              " 'ë²„ìŠ¤ê°€ 8ì‹œ10ë¶„êº¼ê°€ ìˆë‹¤.',\n",
              " 'ì—‘ì†Œ ë‚˜ì™”ë‹¤.',\n",
              " 'ë¡±íŒ¨ë”©ì´ ì•„ë‹ˆë”ë¼ë„ ë¡±íŒ¨ë”©ì„ ì…ìœ¼ë©´ ë¡±íŒ¨ë”©ì´ ëœë‹¤.',\n",
              " 'ë§Œë…„í•„ì€ ì‰í¬ë¥¼ ë„£ì–´ì•¼ í•œë‹¤.',\n",
              " 'ê¶ë§ˆì—ì„œ ì›°í‚µìŠ¤ë§ˆìŠ¤í¬ 1400ì›ì— íŒ”ì•˜ë‹¤.',\n",
              " 'ì„¤ê±°ì§€í•˜ëŠ” ê²Œ ë˜ ê³ ì¥ë‚˜ì„œ ë¬¼ì´ ì‚¬ë°©ì— íŠ€ê³  ìˆë‹¤.',\n",
              " 'ì»¤ë²„ ì–¼ë£©ì´ ë§ë‹¤ê³  ë¯¸ë¦¬ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.',\n",
              " 'ì•„ë¹ ê°€ ê³µê³  ì „ì— ëˆì„ ë„£ì–´ì•¼ í•œë‹¤.',\n",
              " 'ì•„ì´ìŠ¤í¬ë¦¼ ë¨¹ê³  ì±…ì„ ì½ì–´ì£¼ê³  ìˆë‹¤.',\n",
              " 'ì¬ë‚œì§€ì›ê¸ˆ í„¸ê¸°ê°€ ì•„ì§ ë‚¨ì•˜ëŠ”ë° ì‹ë¹„ë¡œ ì“°ê¸°ë¡œ í–ˆë‹¤.',\n",
              " 'íŒŒë‘ìƒ‰ ê·€ì—¬ìš´ ë²„ìŠ¤ë¥¼ ë‹¤ì‹œ ì˜¬ë¼ì™”ë‹¤.',\n",
              " 'êµ¬ì²œêµ¬ë°±ì›ì€ ë‚´ íŒ¬í‹°ê°’ì´ë‹¤.']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq_rhUMELQox",
        "outputId": "8a6f6cf2-7461-4ba3-f39b-922611c0dd61"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ë©˜ë¬´ìƒ¤ê°€ ì—†ì–´ì ¸ì„œ ìŠ¬í”„ê³  ë¡¯ë°ëª°ì— ë‹¤ì–‘í•œ ìŒì‹ì ì´ ìƒê²¨ì„œ ê°€ë³´ê¸°ë¡œ í–ˆë‹¤.'],\n",
              " ['íŒêµì—ì„œ ê°€ëŠ” ì¤‘ì¸ë° 7ì‹œ 30ë¶„ì— ë„ì°©í•˜ê¸°ëŠ” í˜ë“¤ ê²ƒ ê°™ë‹¤.'],\n",
              " ['ë„ì°©í•˜ê¸° 4ë²ˆì§¸ ì „ ì •ê±°ì¥ì—ì„œ ë§í•´ì£¼ê¸°ë¡œ í•œë‹¤.'],\n",
              " ['ë‘˜ ë‹¤ ì°¨ê°€ ë§ì´ ë§‰í˜€ ë¨¼ì € ë„ì°©í•œ ì‚¬ëŒì´ ë¯¸ë¦¬ ì‹œì¼œë†“ê¸°ë¡œ í•œë‹¤.'],\n",
              " ['ë¹„ê°€ ê±°ì˜ ê·¸ì¹œ ê²ƒ ê°™ê³  ì¶”ì›Œì§„ë‹¤ê³  í•˜ë‹ˆ ë”°ë“¯í•˜ê²Œ ì…ê³  ë‹¤ë‹ˆë¼ê³  í•œë‹¤.'],\n",
              " ['ìœ ì—˜ë„ ë‚˜ì´ ì œí•œì´ ë³€ê²½ëëŠ”ì§€ ì›ë˜ 65ì„¸ì˜€ëŠ”ë° ì•ˆ ë¼ì„œ ì €ì¶• ê°™ì€ ê±¸ë¡œ ì„¤ê³„ë¥¼ í•´ ë³´ë¼ê³  í•œë‹¤.'],\n",
              " ['í•œíŒŒê°€ ì˜¨ë‹¤ë”ë‹ˆ ì´ë²ˆ ê²¨ìš¸ì€ ë³„ë¡œ ì•ˆ ì¶¥ë‹¤.'],\n",
              " ['ê³µì¸ ì¸ì¦ì„œ ë¹„ë°€ë²ˆí˜¸ê°€ 3ë²ˆì§¸ í‹€ë ¤ì„œ ì°¨ë¶„íˆ ëˆŒëŸ¬ë´ì•¼ê² ë‹¤.'],\n",
              " ['ì´ë²ˆ ë‹¬ ì¹´ë“œê°’ì„ ë„ˆë¬´ ë§ì´ ì¨ì„œ ë§ˆì‚¬ì§€ë¥¼ ëª» ë°›ìœ¼ëŸ¬ ê°„ë‹¤ê³  í•˜ê³  ì–´ë””ì— ê·¸ë ‡ê²Œ ì¼ëŠ”ì§€ í™•ì¸í•œë‹¤.'],\n",
              " ['ì¹´í˜ë¡œ ì˜¨ íƒë°°ë¥¼ ë‹¤ ë°›ì•˜ëŠ”ì§€ ë¬»ê³  5ì‹œ í‡´ê·¼ ì§ì „ì— ë°›ì•˜ë‹¤ê³  ëŒ€ë‹µí•œë‹¤.'],\n",
              " ['ì£¼ë§ì— ë¯¸ì„¸ë¨¼ì§€ê°€ ì‹¬í•˜ì§€ ì•Šì•„ì„œ ì‚°ì±…í•  ìˆ˜ ìˆê¸°ë¥¼ ë°”ë¼ê³  ìˆë‹¤.'],\n",
              " ['8ì‹œ 10ë¶„ ë²„ìŠ¤ê°€ ìˆëŠ”ë° ì•ˆì‚°ìœ¼ë¡œ ê°€ëŠ” ê±°ë¼ê³  í•˜ë‹ˆ ì•ˆì‚°ì— ë‚´ë¦¬ë©´ ë°ë ¤ë‹¤ì¤€ë‹¤ë©° ê³ ë¯¼ì„ í•´ë´ì•¼ê² ë‹¤ê³  í•œë‹¤.'],\n",
              " ['ì—‘ì†Œ ì¹´ì´ì˜ ì§‘ì´ ë‚˜ í˜¼ì ì‚°ë‹¤(ë‚˜í˜¼ì‚°)ì— ë‚˜ì™”ëŠ”ë° ì¸ìœ„ì ì´ê³  ì¸í…Œë¦¬ì–´ì— ëˆì„ ë§ì´ ì“´ ëŠë‚Œì´ë‹¤.'],\n",
              " ['ë°–ì´ ì¶”ì›Œì„œ ë¬´ì¡°ê±´ íŒ¨ë”©ì„ ì…ê³  ë§Œë‚˜ìê³  í•œë‹¤.'],\n",
              " ['ë§Œë…„í•„ê³¼ ë±€ì´ ë¶™ì€ ë””ìì¸ì˜ ë³¼íœì— ëŒ€í•´ ì´ì•¼ê¸°í•œë‹¤.'],\n",
              " ['ì˜¤ëŠ˜ ë§ˆíŠ¸ì—ì„œ ì›”í‚µìŠ¤ ë§ˆìŠ¤í¬ê°€ 1400ì›ì— íŒ”ì•˜ë‹¤ê³  í•˜ë©° ì˜¤í”„ë¼ì¸ì— ì ì  í’€ë¦¬ëŠ” ê±° ê°™ë‹¤ê³  í•œë‹¤.'],\n",
              " ['í•˜ë‚˜ë¥¼ ê³ ì¹˜ë©´ ë‹¤ë¥¸ í•˜ë‚˜ê°€ ê³ ì¥ ë‚˜ëŠ”ë° ë„ˆë¬´ ì‹¼ ê²ƒì„ ì¼ëŠ”ì§€ ì„¤ê±°ì§€í•˜ëŠ” ë° ë¬¼ì´ ë‚˜ì˜¤ëŠ” ì£¼ë°© í—¤ë“œê°€ ê³ ì¥ì´ ë‚¬ë‹¤.'],\n",
              " ['ì–¼ë£©ì´ ë§ì€ ë§¤íŠ¸ë¦¬ìŠ¤ íŒë§¤ì— ëŒ€í•´ ì´ì•¼ê¸°í•œë‹¤.'],\n",
              " ['ì—„ë§ˆëŠ” 2ìˆœìœ„ë¼ì„œ ì›”ìš”ì¼ì— ëˆì„ ë„£ì–´ì•¼ í•œë‹¤.'],\n",
              " ['ì•„ì´ê°€ ë‚®ì ì„ ì˜ ìì„œ ëŠ¦ê²Œ ì¬ìš´ë‹¤ê³  ì´ì•¼ê¸°í•œë‹¤.'],\n",
              " ['ë‚¨ì ì¹œêµ¬ì˜ ì¬ë‚œì§€ì›ê¸ˆì„ í„¸ê¸° ìœ„í•´ ì¸ì²œì— ê°€ëŠ” ì¤‘ì´ë‹¤.'],\n",
              " ['íŒŒë‘ìƒ‰ ì¥ë¯¸ëª¨ì–‘ ë¬´ëŠ¬ê°€ ìˆëŠ” ë¬¼ê±´ì´ ê·€ì—½ë‹¤.'],\n",
              " ['ì¹œêµ¬ë“¤ì—ê²Œ 39000ì›ì”© ë³´ë‚´ë¼ê³  í•˜ë‹ˆ ì•Œì•˜ë‹¤ê³  í•œë‹¤.']]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_scores = corpus_bleu(references, summaries, smoothing_function=SmoothingFunction().method4)\n",
        "rouge_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3nNsDHvKyhk",
        "outputId": "a5c9d48f-e08b-43fe-b052-374c40796c06"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10047413670532138"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRGCWeIqxpfF",
        "outputId": "63c36ccf-43b6-429f-8609-c8f98ea2b49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: í‡´ê·¼ê¸¸ì— 365ì½”ë„ˆ ë“¤ëŸ¬ì„œ ì´ì²´í–ˆìŒ! OTPëŠ” ì¡°ë§Œê°„ ì€í–‰ê°€ì•¼ê² ë‹¤ otpê°€..ë­ì•¼.. ë‚œ..ëª°ë¼...ì˜¤í‹°í”¼..ì²˜ìŒë“¤ì–´ë´ ì•„ ëª°ë¼? ê·¸..ì¸í„°ë„·ê³„ì¢Œ? ê·¸ëŸ°ê±°ì˜ëª°ë¼ ì¸í„°ë„·ë±…í‚¹í• ë•Œ ì“°ëŠ” 1íšŒìš© ë¹„ë°€ë²ˆí˜¸ ë³´ì—¬ì£¼ëŠ” ì¡°ê·¸ë§ˆí•œ ê±° ì•„ì•„ì•„ ê·¸..ê·¸ê±°.. ë§¤ë²ˆ ê±°ë˜ì‹œ 1íšŒìš© ë¹„ë²ˆë³´ì—¬ì£¼ã…• ì¸í„°ë„· ë±…í‚¹ì´ í¸í•´ì ¸ìš”! ê³µì¸ì¸ì¦ì„œê·¸ëŸ°ê±°ë¹„ìŠ·í•œê±°? íˆ¬ëª…í•œì¹´ë“œ? ì•„ ë‚´ê»€ ì¹´ë“œí˜•ì•„ë‹˜ ì˜›ë‚ ì—” ë³´ì•ˆì¹´ë“œ ì˜€ë‹¤ ê³µì¸ì¸ì¦ì„œë•Œ ì“°ëŠ” ì¹´ë“œ ì•„ê·¸ë˜..? ì¸í„°ë„·ë±…í‚¹ ê³µì¸ì¸ì¦ì„œ+ë³´ì•ˆì¹´ë“œê°€ ì—¿ê°™ì•„ë³´ì—¬ì„œ ì•ˆì“´ë‹¤.. ê·¼ë° ê·¸ê²Œ OTPë¡œ ë°”ë€Œì—ˆë‹¤ ì´ì‰..í• ë¯¸ëŠ” ìš”ì¦˜ ì–´ì©Œêµ¬ ê·¸ë ê±°ëª°ë¼\n",
            "Summary: ì¸í„°ë„·ë±…í‚¹ì„ í•  ë•Œ ì“°ëŠ” 1íšŒìš© ë¹„ë°€ë²ˆí˜¸ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒ ê°™ë‹¤.\n"
          ]
        }
      ],
      "source": [
        "input_text = train_df.iloc[0,0]\n",
        "\n",
        "# ë¬¸ì¥ì„ í† í°í™”í•˜ê³  ì…ë ¥ ì¸ì½”ë”©\n",
        "inputs = kobart_tokenizer(input_text, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "\n",
        "# ëª¨ë¸ì— ì…ë ¥ ì „ë‹¬í•˜ì—¬ ìš”ì•½ ìƒì„±\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=100, early_stopping=True)\n",
        "summary = kobart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# ìš”ì•½ ì¶œë ¥\n",
        "print(\"Input:\", input_text)\n",
        "print(\"Summary:\", summary)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcNq9IpdxnCoTYAbS6B+NH",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}